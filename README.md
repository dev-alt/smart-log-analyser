# Smart Log Analyser

A high-performance CLI tool for analysing Nginx access logs with real-time monitoring capabilities.

## Overview

Smart Log Analyser is designed to help system administrators and developers gain insights from their Nginx access logs. It provides statistical analysis, error pattern detection, traffic analysis, and real-time monitoring with configurable alerting.

## Features

### Phase 1 (MVP) âœ…
- [x] Parse standard Nginx access log formats (common/combined)
- [x] Basic statistics: request counts, status code distribution, top IPs, top URLs
- [x] Time range filtering
- [x] Clean console output with formatting
- [x] SSH remote log file download
- [x] Multi-file analysis support

### Phase 2 (Analytics) âœ…
- [x] Enhanced statistics with percentages and visual formatting
- [x] HTTP method analysis (GET, POST, etc.)
- [x] Data transfer analytics (total bytes, average response size)
- [x] Unique visitor/resource counting
- [x] Improved console output with emojis and structured display
- [x] **Bot detection and traffic analysis** (human vs automated traffic)
- [x] **File type analysis** (CSS, JavaScript, images, dynamic content)
- [x] **Top bot/crawler identification** (Googlebot, curl, monitoring tools)
- [x] **Export functionality** (JSON and CSV formats with detailed breakdowns)
- [x] **Detailed drill-down analysis** (individual status codes, error URLs, large requests)
- [x] **Error pattern detection** (4xx/5xx URLs, failure analysis)
- [x] **Traffic pattern analysis** (hourly breakdowns, peak detection, visual charts)
- [x] **Peak traffic detection** (automatic identification of traffic spikes)
- [x] **Response time analysis and percentiles** (P50, P95, P99 using response size as proxy)
- [x] **Geographic IP analysis** (country/region detection, private network identification)
- [x] **Advanced security analysis** (attack pattern detection, anomaly detection, threat scoring)
- [x] **Compressed file support** (automatic .gz decompression, rotated log files)

### Phase 3 (Advanced Analytics) ğŸš€
- [x] **HTML report generation with embedded charts** (Interactive reports with Chart.js visualizations)
- [ ] Historical trend analysis (compare periods, track degradation)
- [ ] ASCII charts and terminal visualizations
- [ ] Advanced query language for complex filtering
- [ ] Database integration (SQLite, PostgreSQL export)
- [ ] Plugin architecture for custom analyzers

## Installation

### From Source
```bash
git clone https://github.com/dev-alt/smart-log-analyser.git
cd smart-log-analyser
go build -o smart-log-analyser
```

### Using Go Install
```bash
go install github.com/dev-alt/smart-log-analyser@latest
```

## Project Structure

The Smart Log Analyser uses the following folder structure:

```
smart-log-analyser/
â”œâ”€â”€ config/          # Configuration files (future use)
â”œâ”€â”€ downloads/       # Downloaded log files from remote servers
â”œâ”€â”€ output/          # Generated reports and export files
â”œâ”€â”€ testdata/        # Sample log files for testing
â”œâ”€â”€ pkg/            # Go packages (parser, analyser, remote)
â”œâ”€â”€ cmd/            # CLI command implementations
â””â”€â”€ scripts/        # Utility scripts (security checks, etc.)
```

**Important**: The `downloads/` and `output/` folders are excluded from git to prevent accidentally committing sensitive log files or large output files.

## Interactive Menu System ğŸ¯

Smart Log Analyser now features an **interactive menu system** that launches when you run the program without arguments. This provides a user-friendly interface for all operations.

### Launching the Interactive Menu
```bash
# Simply run the program to launch the interactive menu
./smart-log-analyser
```

### Menu Features
- **ğŸ“‚ Analyse Local Log Files**: Browse and select log files with guided analysis
- **ğŸŒ Download & Analyse Remote Logs**: Manage remote server connections and downloads
- **ğŸ“ˆ Generate HTML Report**: Create interactive reports with custom settings
- **ğŸ”§ Configuration & Setup**: Configure servers, preferences, and export settings
- **ğŸ“š Help & Documentation**: Built-in help and guidance
- **ğŸšª Exit**: Clean exit from the application

### Interactive Workflows
The menu system guides you through:
- **File Selection**: Browse directories, use wildcards, or manually enter paths
- **Time Range Filtering**: Set custom date/time ranges for analysis
- **Export Options**: Choose from HTML, JSON, CSV formats with custom settings
- **Analysis Configuration**: Select detailed analysis options
- **Progress Tracking**: Real-time progress indicators for long operations

## Quick Start

### Interactive Mode (Recommended)
```bash
# Launch interactive menu for guided experience
./smart-log-analyser

# Follow the prompts to:
# 1. Select "Analyse Local Log Files"
# 2. Choose your log files
# 3. Configure analysis options
# 4. Generate reports
```

### Command Line Mode
```bash
# Analyse a single log file
./smart-log-analyser analyse /var/log/nginx/access.log

# Analyse multiple log files together
./smart-log-analyser analyse /var/log/nginx/access.log /var/log/nginx/access.log.1

# Analyse compressed log files (.gz)
./smart-log-analyser analyse /var/log/nginx/access.log.1.gz

# Analyse all downloaded files using wildcard (supports compressed files)
./smart-log-analyser analyse ./downloads/*.log
./smart-log-analyser analyse ./downloads/*.gz

# Analyse all log files including compressed and rotated logs
./smart-log-analyser analyse /var/log/nginx/access.log* /var/log/nginx/error.log*

# Filter by time range
./smart-log-analyser analyse /var/log/nginx/access.log --since="2024-08-20 00:00:00" --until="2024-08-20 23:59:59"

# Get top 10 IPs and URLs
./smart-log-analyser analyse /var/log/nginx/access.log --top-ips=10 --top-urls=10

# Test with sample data
./smart-log-analyser analyse testdata/sample_access.log

# Show detailed breakdown with individual status codes and error analysis
./smart-log-analyser analyse /var/log/nginx/access.log --details

# Export results for further analysis (files saved to output/ folder)
./smart-log-analyser analyse ./downloads/*.log --export-json=output/detailed_report.json --export-csv=output/summary.csv

# Generate interactive HTML report with charts and visualizations
./smart-log-analyser analyse ./downloads/*.log --export-html=output/report.html --html-title="Production Server Analysis"

# Generate multiple export formats simultaneously
./smart-log-analyser analyse ./downloads/*.log --export-html=output/report.html --export-json=output/data.json --export-csv=output/summary.csv --details

# Analyze traffic patterns and identify peak hours
./smart-log-analyser analyse /var/log/nginx/access.log* --details
```

### Remote Server Access
```bash
# Create SSH configuration file (only if doesn't exist)
./smart-log-analyser download --init

# Test SSH connections
./smart-log-analyser download --test

# List available log files without downloading
./smart-log-analyser download --list

# Download ALL access log files (default behavior)
./smart-log-analyser download

# Download single log file only
./smart-log-analyser download --single

# Download limited number of files  
./smart-log-analyser download --max-files 5

# Download from specific server
./smart-log-analyser download --server your-server.com

# Analyse downloaded files
./smart-log-analyser analyse ./downloads/*.log
```

## HTML Reports ğŸ“Š

The Smart Log Analyser can generate beautiful, interactive HTML reports with embedded charts and visualizations.

### Features
- **Interactive Charts**: Powered by Chart.js with responsive design
- **Professional Layout**: Clean, modern interface with Bootstrap CSS
- **Comprehensive Analysis**: All analytics displayed with visual charts
- **Mobile Friendly**: Responsive design works on all devices
- **Print Ready**: Optimized styling for PDF generation

### Chart Types
- **Traffic Analysis**: Pie charts for human vs bot traffic
- **Status Code Distribution**: Doughnut charts for response codes
- **Hourly Traffic Patterns**: Line charts showing traffic over time
- **Response Size Analysis**: Bar charts for response time proxies
- **Geographic Distribution**: Bar charts for traffic by region
- **File Type Analysis**: Stacked bar charts for content types

### HTML Report Generation
```bash
# Basic HTML report
./smart-log-analyser analyse logs/ --export-html=output/report.html

# Custom title and detailed analysis
./smart-log-analyser analyse logs/ --export-html=output/report.html --html-title="Production Analysis" --details

# Multiple formats with HTML report
./smart-log-analyser analyse logs/ --export-html=output/report.html --export-json=output/data.json --details
```

### Opening HTML Reports
```bash
# Open in default browser (Linux)
xdg-open output/report.html

# Open in default browser (macOS)
open output/report.html

# Open in default browser (Windows)
start output/report.html
```

## Dual Operation Modes

Smart Log Analyser supports both **interactive menu mode** and **traditional CLI mode**:

### When to Use Each Mode

**ğŸ¯ Interactive Mode** - Best for:
- New users learning the system
- Complex analysis with multiple options
- Guided report generation
- Configuration and setup tasks
- Exploring available features

**âš¡ CLI Mode** - Best for:
- Automation and scripting
- Batch processing workflows
- Integration with CI/CD pipelines
- Power users who know exact commands
- Remote server usage via SSH

### Switching Between Modes
```bash
# Interactive mode (menu-driven)
./smart-log-analyser

# CLI mode (direct commands)
./smart-log-analyser analyse logs/ --export-html=output/report.html
./smart-log-analyser download --test
./smart-log-analyser --help
```

Both modes provide access to the same powerful analysis features, just with different user interfaces optimized for different use cases.

## Example Output

```
ğŸ“‚ Analysing 3 log file(s)...

  [1/3] Processing: ./downloads/server1_20240823_access.log
    âœ… Parsed 1247 entries
  [2/3] Processing: ./downloads/server1_20240823_access.log.1
    âœ… Parsed 2156 entries
  [3/3] Processing: ./downloads/server1_20240823_access.log.2
    âœ… Parsed 893 entries

ğŸ“Š Combined Analysis Results (4296 total entries):
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                   Smart Log Analyser Results                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Overview
â”œâ”€ Total Requests: 4,296
â”œâ”€ Unique IPs: 127
â”œâ”€ Unique URLs: 48
â”œâ”€ Data Transferred: 2.1 GB
â”œâ”€ Average Response Size: 512.3 KB
â””â”€ Date Range: 2024-08-22 10:15:30 to 2024-08-23 23:59:45

ğŸ¤– Traffic Analysis
â”œâ”€ Human Traffic: 3,264 (76.0%)
â”œâ”€ Bot/Automated: 1,032 (24.0%)

ğŸ” Top Bots/Crawlers
â”œâ”€ Googlebot: 287 requests (6.7%)
â”œâ”€ Bingbot: 156 requests (3.6%)
â”œâ”€ Facebook Bot: 89 requests (2.1%)
â”œâ”€ cURL: 67 requests (1.6%)
â”œâ”€ Monitoring Bot: 43 requests (1.0%)

ğŸ“ File Type Analysis
â”œâ”€ Dynamic/HTML: 2,847 requests (66.3%) - 1.8 GB total, 659.2 KB avg
â”œâ”€ CSS: 542 requests (12.6%) - 85.4 MB total, 161.2 KB avg
â”œâ”€ JavaScript: 398 requests (9.3%) - 124.7 MB total, 320.8 KB avg
â”œâ”€ Images: 287 requests (6.7%) - 67.8 MB total, 241.7 KB avg
â”œâ”€ Fonts: 89 requests (2.1%) - 15.2 MB total, 174.9 KB avg

ğŸ“ˆ Traffic Patterns
â”œâ”€ Average Requests/Hour: 179.0
â”œâ”€ Peak Hour: 14:00 (Afternoon)  
â”œâ”€ Quietest Hour: 03:00 (Night)
â””â”€ Hourly Breakdown:
   â”œâ”€ 08:00: 98 requests (2.3%) [â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 09:00: 156 requests (3.6%) [â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 10:00: 234 requests (5.4%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 11:00: 298 requests (6.9%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 12:00: 432 requests (10.1%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 13:00: 578 requests (13.5%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 14:00: 892 requests (20.8%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] â† Peak
   â”œâ”€ 15:00: 567 requests (13.2%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘]
   â”œâ”€ 16:00: 341 requests (7.9%) [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]

ğŸ”¥ Traffic Peaks Detected
â”œâ”€ Peak #1: 2024-08-22 14:00 - 892 requests (1 hour)
â”œâ”€ Peak #2: 2024-08-22 13:00 - 578 requests (1 hour)

â±ï¸  Response Size Analysis (Proxy for Response Time)
â”œâ”€ Average Response: 512.3 KB
â”œâ”€ Median (P50): 234.5 KB
â”œâ”€ 95th Percentile: 1.2 MB
â”œâ”€ 99th Percentile: 2.8 MB
â”œâ”€ Range: 128 B - 3.4 MB
â”œâ”€ Slowest Endpoints (by size):
â”‚  â”œâ”€ /api/large-report: 3.4 MB
â”‚  â”œâ”€ /downloads/document.pdf: 2.1 MB
â””â”€ Fastest Endpoints (by size):
   â”œâ”€ /api/status: 128 B
   â”œâ”€ /health: 156 B

ğŸŒ Geographic Distribution
â”œâ”€ Local/Private: 1,247 (29.0%)
â”œâ”€ Cloudflare CDN: 892 (20.8%)
â”œâ”€ Countries (15 total):
â”‚  â”œâ”€ United States: 1,156 requests (26.9%)
â”‚  â”œâ”€ United Kingdom: 234 requests (5.4%)
â”‚  â”œâ”€ Australia/NZ: 189 requests (4.4%)
â”‚  â”œâ”€ Germany: 167 requests (3.9%)
â”‚  â”œâ”€ Canada: 143 requests (3.3%)
â””â”€ Regions:
   â”œâ”€ North America: 1,299 requests (30.2%)
   â”œâ”€ Europe: 567 requests (13.2%)
   â”œâ”€ Asia-Pacific: 234 requests (5.4%)
   â”œâ”€ Oceania: 189 requests (4.4%)

ğŸ” Security Analysis (Threat Level: LOW, Score: 92/100)
â”œâ”€ Total Threats Detected: 12
â”œâ”€ Suspicious IPs: 3
â”œâ”€ Anomalies Detected: 1
â”œâ”€ Attack Breakdown:
â”‚  â”œâ”€ SQL Injection: 4 attempts
â”‚  â”œâ”€ XSS Attempts: 2
â”‚  â”œâ”€ Directory Traversal: 3 attempts
â”‚  â”œâ”€ Brute Force: 2 attempts
â”‚  â”œâ”€ Scanning Activity: 1 instances
â”œâ”€ Top Threat IPs:
â”‚  â”œâ”€ 203.0.113.1: 15 requests (Score: 45, sql_injection, scanner)
â”‚  â”œâ”€ 198.51.100.42: 12 requests (Score: 35, xss, directory_traversal)
â””â”€ Recent High-Severity Threats:
   â”œâ”€ [14:23:15] Sql Injection from 203.0.113.1
   â”‚   URL: /search?q=admin' OR 1=1--
   â”‚   Pattern: Boolean-based injection
   â”œâ”€ [14:25:42] Directory Traversal from 198.51.100.42
   â”‚   URL: /files/../../../../etc/passwd
   â”‚   Pattern: Unix-style traversal (../)

ğŸ”§ HTTP Methods
â”œâ”€ GET: 3,892 (90.6%)
â”œâ”€ POST: 347 (8.1%)
â”œâ”€ PUT: 42 (1.0%)
â”œâ”€ DELETE: 15 (0.3%)

ğŸ“ˆ Status Code Distribution
â”œâ”€ 2xx Success: 3,847 (89.5%)
â”œâ”€ 4xx Client Error: 312 (7.3%)
â”œâ”€ 5xx Server Error: 137 (3.2%)

ğŸŒ Top 5 IP Addresses
â”œâ”€ 192.168.1.100: 247 requests (5.7%)
â”œâ”€ 10.0.0.5: 198 requests (4.6%)
â”œâ”€ 203.0.113.1: 156 requests (3.6%)
â”œâ”€ 198.51.100.42: 143 requests (3.3%)
â”œâ”€ 172.16.0.15: 98 requests (2.3%)

ğŸ”— Top 5 URLs
â”œâ”€ /index.html: 89 requests (2.1%)
â”œâ”€ /api/status: 67 requests (1.6%)
â”œâ”€ /assets/style.css: 54 requests (1.3%)
â”œâ”€ /products.html: 43 requests (1.0%)
â”œâ”€ /about.html: 38 requests (0.9%)
```

## Supported Log Formats

Currently supports standard Nginx access log formats:

- **Combined Log Format**: `$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent"`
- **Common Log Format**: `$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent`

### File Format Support

The Smart Log Analyser can process various log file formats:

- **Regular log files**: `access.log`, `error.log`, `nginx.log`
- **Rotated log files**: `access.log.1`, `access.log.2`, `forum.access.log.5`
- **Compressed files**: `access.log.1.gz`, `error.log.14.gz`, `forum.access.log.5.gz`
- **Complex naming**: `example.com.access.log`, `site.error.log.11.gz`

**Supported compression formats:**
- âœ… **Gzip (.gz)** - Automatic decompression during analysis
- ğŸ“‹ **Bzip2 (.bz2)** - Planned for future releases

**File detection patterns:**
- Files ending with `.log`, `.access`, `.error` (with optional numbers)
- Compressed variants with `.gz` extension
- Mixed patterns like `site.access.log.12.gz`

## Project Structure

```
smart-log-analyser/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ root.go           # CLI root command
â”‚   â”œâ”€â”€ analyse.go        # Analysis command
â”‚   â””â”€â”€ download.go       # Remote download command
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ parser/           # Log parsing logic
â”‚   â”œâ”€â”€ analyser/         # Analysis algorithms
â”‚   â””â”€â”€ remote/           # SSH client and configuration
â”œâ”€â”€ testdata/             # Sample log files for testing
â”œâ”€â”€ servers.json.example  # Example SSH configuration
â”œâ”€â”€ main.go               # Application entry point
â””â”€â”€ README.md             # This file
```

## Command Line Options

### `analyse` command

**Usage**: `./smart-log-analyser analyse [log-files...]`

Accepts one or more log files for analysis. When multiple files are provided, they are combined for comprehensive analysis.

**Options**:
- `--since`: Start time for analysis (format: "YYYY-MM-DD HH:MM:SS")
- `--until`: End time for analysis (format: "YYYY-MM-DD HH:MM:SS")
- `--top-ips`: Number of top IP addresses to display (default: 10)
- `--top-urls`: Number of top URLs to display (default: 10)
- `--details`: Show detailed breakdown (individual status codes, error URLs, large requests)
- `--export-json`: Export detailed results to JSON file (e.g., `--export-json=report.json`)
- `--export-csv`: Export detailed results to CSV file (e.g., `--export-csv=report.csv`)

### `download` command

- `--config`: Path to SSH configuration file (default: "servers.json")
- `--server`: Specific server to download from (host name)
- `--output`: Directory to save downloaded files (default: "./downloads")
- `--test`: Test SSH connection without downloading
- `--init`: Create a sample configuration file (will not overwrite existing files)
- `--list`: List available log files without downloading
- `--single`: Download only the main configured log file
- `--max-files`: Maximum number of files to download (default: 10)
- `--all`: Download all access log files (same as default behavior)

## SSH Configuration

The SSH configuration is stored in JSON format. Create it with:

```bash
# Creates servers.json only if it doesn't exist
./smart-log-analyser download --init

# Create with different filename
./smart-log-analyser download --init --config my-servers.json
```

**Note**: The `--init` command will **not overwrite** existing configuration files. If a file already exists, it will display the current configuration instead.

Example `servers.json`:
```json
{
  "servers": [
    {
      "host": "your-server.com",
      "port": 22,
      "username": "root",
      "password": "your-password",
      "log_path": "/var/log/nginx/access.log"
    }
  ]
}
```

âš ï¸ **Security Note**: Store the configuration file securely and restrict permissions (`chmod 600 servers.json`).

## Export and Analysis Features

### ğŸ“Š Export Formats

**JSON Export** (`--export-json`):
- Complete analysis results in structured JSON format
- Includes all metrics, detailed breakdowns, and raw data
- Perfect for programmatic processing or integration with other tools
- Contains individual status codes, bot details, file type statistics

**CSV Export** (`--export-csv`):
- Tabular format suitable for spreadsheet analysis
- Organized by sections (Overview, Status Codes, Top IPs, etc.)
- Includes percentages and detailed metrics
- Easy to import into Excel, Google Sheets, or database systems

### ğŸ” Detailed Analysis Mode (`--details`)

When using the `--details` flag, you get additional insights:
- **Individual Status Codes**: See exact HTTP status codes (200, 404, 500, etc.)
- **Error Analysis**: URLs generating 4xx/5xx errors with frequency counts
- **Large Requests**: Biggest requests by response size to identify heavy resources
- **Enhanced Bot Detection**: More detailed bot breakdown and identification
- **Response Time Analysis**: Percentile analysis using response size as proxy (P50, P95, P99)
- **Geographic Distribution**: Country and region breakdown of IP addresses with CDN detection
- **Security Threat Analysis**: Detailed attack patterns, IP threat scoring, and anomaly detection
- **Compressed File Support**: Seamless processing of .gz files and rotated logs

### ğŸ“ˆ Use Cases

**For System Administrators**:
```bash
# Daily log analysis with export for reporting (including compressed files)
./smart-log-analyser analyse /var/log/nginx/access.log* --export-csv=daily_report.csv --details

# Analyse all log files including rotated and compressed
./smart-log-analyser analyse /var/log/nginx/*.log /var/log/nginx/*.log.* /var/log/nginx/*.gz --details

# Monitor error patterns and investigate issues
./smart-log-analyser analyse /var/log/nginx/access.log --details | grep "Error Analysis" -A 10

# Process downloaded compressed logs efficiently
./smart-log-analyser analyse ./downloads/*.gz --export-json=compressed_analysis.json
```

**For Security Analysis**:
```bash
# Comprehensive security analysis with threat detection
./smart-log-analyser analyse logs/*.log logs/*.gz --export-json=security_analysis.json --details

# Monitor for specific attack patterns and anomalies
./smart-log-analyser analyse /var/log/nginx/*.log* --details | grep -E "(Security|Threat|Anomaly)"

# Process compressed security logs for incident analysis
./smart-log-analyser analyse ./incident_logs/*.gz --details --export-csv=security_report.csv

# Real-world security monitoring example
./smart-log-analyser analyse /var/log/nginx/access.log* /var/log/nginx/error.log* --details
```

## Multi-File Download Features

### ğŸ” Discovery and Listing
```bash
# List all available log files on server
./smart-log-analyser download --list
```

This will show you all access log files including:
- Current log files (`access.log`, `forum.access.log`, etc.)
- Rotated log files (`access.log.1`, `access.log.2`, etc.) 
- Compressed logs (`access.log.gz`, `access.log.12.gz`, etc.)

### ğŸ“¦ Bulk Download Options
```bash
# Download all access log files (up to 10 by default)
./smart-log-analyser download --all

# Download more files (up to 20)
./smart-log-analyser download --all --max-files 20

# Download from specific server only
./smart-log-analyser download --all --server your-server.com
```

### ğŸ“Š Download Behavior
- **Multi-file mode** (default): Downloads all access log files found in the log directory (up to 10 files)
- **Single file mode** (`--single`): Downloads only the configured `log_path` file
- **Smart naming**: Files are saved as `hostname_timestamp_originalname` to avoid conflicts
- **Progress tracking**: Shows download progress for each file with size information
- **Configurable limit**: Use `--max-files` to control how many files to download

## Development

### Prerequisites
- Go 1.18 or higher
- Git

### Building
```bash
go build -o smart-log-analyser
```

### Performance Features

**Compressed File Optimization**:
- Automatic detection of file types based on extensions
- Streaming decompression for memory efficiency
- Large buffer support (1MB) for processing big compressed files
- Concurrent processing capability for multiple files

**File Processing Capabilities**:
- Handles files of any size through streaming
- Memory-efficient processing of compressed archives
- Supports mixed file types in single analysis session
- Robust error handling for corrupted or incomplete files

### Testing
```bash
# Test with sample data
./smart-log-analyser analyse testdata/sample_access.log

# Test help commands
./smart-log-analyser --help
./smart-log-analyser analyse --help
./smart-log-analyser download --help

# Test SSH configuration creation
./smart-log-analyser download --init
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License.

## Roadmap

- **v0.1.0**: Basic log parsing and statistics âœ…
- **v0.1.1**: SSH remote log download âœ…
- **v0.2.0**: Advanced analytics and export features âœ…
- **v0.2.1**: Security analysis and compressed file support âœ…  
- **v0.3.0**: Advanced analytics and visualizations
- **v1.0.0**: Production-ready with comprehensive documentation

## Acknowledgments

Built with:
- [Cobra](https://github.com/spf13/cobra) - CLI framework
- [golang.org/x/crypto](https://pkg.go.dev/golang.org/x/crypto) - SSH connectivity
- Go standard library for log parsing and analysis

## Security Notes

### ğŸ” Credential Security
- SSH configuration files contain sensitive credentials and are **automatically excluded** from version control
- Use secure file permissions: `chmod 600 servers.json`
- Never commit real passwords, server IPs, or SSH keys to git
- Use the provided `servers.json.example` as a template

### ğŸ›¡ï¸ Production Security Recommendations
- **Use SSH key authentication** instead of passwords in production
- **Restrict network access** to log servers (VPN, firewall rules)
- **Rotate credentials regularly** and use strong passwords
- **Monitor access logs** for unauthorized usage
- **Consider log aggregation systems** instead of direct server access

### âš ï¸ Development Security
- Real server credentials in `servers.json` are excluded from git commits
- Test connections are logged - avoid using production servers for testing
- Downloaded log files may contain sensitive data - they are also excluded from git
- Review `.gitignore` regularly to ensure all sensitive patterns are covered
- Use `./scripts/check-sensitive-data.sh` before commits to scan for sensitive data

## Development Guidelines

### ğŸ“‹ Development Workflow (Mandatory)
All contributors must follow these steps for every development session:

1. **Documentation First**: Update README.md and relevant docs for new features
2. **Security Review**: Check all changes for sensitive data before committing  
3. **Development Log**: Update `.development_log.md` with session details
4. **Testing**: Verify new features work and existing functionality remains intact
5. **Git Workflow**: Stage, commit with descriptive message, and push to GitHub

See `DEVELOPMENT_RULES.md` for comprehensive development standards and security practices.

### ğŸ” Security Checklist
Before every commit, verify:
- [ ] No real passwords, API keys, or tokens in any files
- [ ] No SSH private keys or certificates committed
- [ ] No real server IPs or sensitive hostnames
- [ ] `.gitignore` updated for new sensitive file patterns  
- [ ] Documentation updated with security warnings
- [ ] Example files use placeholder values only